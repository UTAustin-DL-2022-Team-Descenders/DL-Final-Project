{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import sys, os\n",
    "import pystk\n",
    "import ray\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device = ', device)\n",
    "ray.init(logging_level=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc231b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_agent.agents.subnets.actors import SteeringActor, DriftActor, SpeedActor\n",
    "from state_agent.agents.subnets.planners import PlayerPuckGoalPlannerActor\n",
    "from state_agent.agents.subnets.agents import Agent, BaseTeam\n",
    "from state_agent.agents.subnets.utils import Rollout, run_soccer_agent, rollout_many, show_trajectory_histogram, load_model, save_model\n",
    "from state_agent.agents.subnets.rewards import SoccerBallDistanceObjective\n",
    "from state_agent.agents.subnets.features import get_distance_cart_to_puck\n",
    "from state_agent.trainers.train_policy_gradient import reinforce, SoccerReinforcementConfiguration\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3195c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(), train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializations(actor_class):    \n",
    "    distance_objective = SoccerBallDistanceObjective(150)\n",
    "    many_actors = [actor_class() for i in range(100)]\n",
    "\n",
    "    data = rollout_many([\n",
    "        Agent(actor, accel=0.05) for actor in many_actors\n",
    "    ], randomize=True, n_steps=600)\n",
    "\n",
    "    good_initialization = many_actors[ np.argmax([distance_objective.calculate_state_score(d[-1]) for d in data]) ]\n",
    "    bad_initialization = many_actors[ np.argmin([distance_objective.calculate_state_score(d[-1]) for d in data]) ]\n",
    "    \n",
    "    return good_initialization, bad_initialization\n",
    "\n",
    "good_initialization, _ = get_initializations(SteeringActor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_initialization = best_steering_net\n",
    "action_net = copy.deepcopy(good_initialization.action_net)\n",
    "actors = [SteeringActor(action_net)]\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    return Agent(*args, accel=0.05, target_speed=10.0, **kwargs)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_steering_net = reinforce(actors[0], actors, config, \n",
    "                              n_epochs=5, n_iterations=500, n_trajectories=200, n_validations=100, T=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(best_steering_net), accel=0.1), randomize=True, ball_location=[-6., -60.], player_location=[-20, 0, -50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8eaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the steering actor\n",
    "save_model(best_steering_net, 'modules/steering/agent.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a98817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the steering actor\n",
    "best_steering_net = load_model('modules/steering/agent.th', model=SteeringActor().action_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the speed actor\n",
    "good_initialization_speed, _ = get_initializations(SpeedActor)\n",
    "\n",
    "action_net = copy.deepcopy(good_initialization_speed.action_net)\n",
    "actors = [SteeringActor(best_steering_net, train=False), SpeedActor(action_net)]\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    reverse = np.random.uniform(0, 1) < 0.1\n",
    "    speed = np.random.normal(10, 5) * (-1.0 if reverse else 1.0)\n",
    "    return Agent(*args, target_speed=speed, **kwargs)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_speed_net = reinforce(actors[1], actors, config, \n",
    "                              n_epochs=5, n_iterations=500, n_trajectories=200, n_validations=100, T=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee85cd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(best_steering_net), SpeedActor(best_speed_net), target_speed=-5.0), randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_speed_net, 'modules/speed/agent.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the speed actor\n",
    "best_speed_net = load_model('modules/speed/agent.th', model=SpeedActor().action_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ec216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the player goal scoring planner\n",
    "\n",
    "def create_planner_actor():\n",
    "    return PlayerPuckGoalPlannerActor(\n",
    "        SpeedActor(best_speed_net),\n",
    "        SteeringActor(best_steering_net)\n",
    "    )\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    return Agent(*args, accel=0.1, **kwargs)\n",
    "\n",
    "def rollout_initializer(world_info, randomize, **kwargs):\n",
    "        \n",
    "    #wall_case = np.random.uniform(0, 1.0) < 0\n",
    "    wall_case = False\n",
    "    \n",
    "    # generate a rollout where the player and puck are near each other\n",
    "    #position = np.random.uniform(low=-10, high=10, size=(2))\n",
    "    offset = [np.random.uniform(-0.2, 0.2), -6]    \n",
    "    world_info.set_ball_location((position[0], 1, position[1]), (0, 0, 0))        \n",
    "    \n",
    "    if wall_case:\n",
    "        player_location = [20, 1, 62]\n",
    "    else:        \n",
    "        player_location = [position[0] + offset[0], 1, position[1] + offset[1]]\n",
    "    world_info.set_kart_location(0, player_location, [0, 0, 0, 1.0], 0)\n",
    "        \n",
    "def post_epoch(actor, context):\n",
    "    # show a histogram of distances\n",
    "    show_trajectory_histogram(context.trajectories, get_distance_cart_to_puck, max=60, bins=20)\n",
    "    plt.hist(context.rewards) \n",
    "    plt.title(\"Rewards\")\n",
    "    plt.show()\n",
    "    plt.hist(context.actions, 4, range=(0, 4)) \n",
    "    plt.title(\"Actions\")\n",
    "    plt.show()\n",
    "    print(np.sum(np.array(context.actions) == 0), np.sum(np.array(context.actions) == 1), np.sum(np.array(context.actions) == 2))\n",
    "\n",
    "good_initialization_planner, _ = get_initializations(create_planner_actor)\n",
    "\n",
    "#action_net = copy.deepcopy(good_initialization_planner.action_net)\n",
    "actors = [PlayerPuckGoalPlannerActor(SpeedActor(best_speed_net), SteeringActor(best_steering_net), action_net)]\n",
    "\n",
    "# give it a positive random weight to make it the worst case\n",
    "#action_net.net[0].weight = torch.nn.Parameter(torch.Tensor([[np.random.uniform(0, 1.0)]]))\n",
    "\n",
    "#starting_weight = action_net.net[0].weight.clone()\n",
    "#print(\"Starting weight\", action_net.net[0].weight)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "config.rollout_initializer = rollout_initializer\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_planner_net = reinforce(actors[0], actors, config, \n",
    "                              n_epochs=4, n_iterations=1000, n_trajectories=200, n_validations=20, T=1,\n",
    "                              epoch_post_process=post_epoch\n",
    "                    )\n",
    "print(best_planner_net.net[0].weight)\n",
    "print(action_net.net[0].weight)\n",
    "\n",
    "#assert(action_net.net[0].weight != starting_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75589ada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_planner_net = action_net\n",
    "data = run_soccer_agent(Agent( \n",
    "    PlayerPuckGoalPlannerActor(\n",
    "        speed_net=SpeedActor(best_speed_net),\n",
    "        steering_net=SteeringActor(best_steering_net), \n",
    "        action_net=best_planner_net        \n",
    "    ), accel=0.1\n",
    "), randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the planner actor\n",
    "save_model(best_planner_net, 'modules/planner/agent.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the planner actor\n",
    "best_planner_net = load_model('modules/planner/agent.th', model=PlayerPuckGoalPlannerActor(best_speed_net, best_steering_net).action_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e0acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_rollout_soccer = Rollout.remote(400, 300, mode=\"soccer\", players=[(0, False, \"tux\")], num_karts=1)\n",
    "data = run_soccer_agent(Agent( \n",
    "    PlayerPuckGoalPlannerActor(\n",
    "        speed_net=SpeedActor(best_speed_net),\n",
    "        steering_net=SteeringActor(best_steering_net), \n",
    "        action_net=best_planner_net        \n",
    "    )\n",
    "), rollout=viz_rollout_soccer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851efde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
