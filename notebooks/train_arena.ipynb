{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.7', ray_version='1.12.0', ray_commit='f18fc31c7562990955556899090f8e8656b48d2d', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:65212', 'raylet_socket_name': 'tcp://127.0.0.1:58617', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\Jgutt\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-05-02_17-07-14_768329_14080', 'metrics_export_port': 64894, 'gcs_address': '127.0.0.1:64491', 'address': '127.0.0.1:64491', 'node_id': '03f50b5062b3e7ea8c7926de91f480e1b0591894611d5614d5787e11'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import sys, os\n",
    "import pystk\n",
    "import ray\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device = ', device)\n",
    "ray.init(logging_level=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc231b8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'state_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17560/3320426353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstate_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSteeringActor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDriftActor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpeedActor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstate_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplanners\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlayerPuckGoalPlannerActor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstate_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseTeam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstate_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRollout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_soccer_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrollout_many\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_trajectory_histogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstate_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSoccerBallDistanceObjective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'state_agent'"
     ]
    }
   ],
   "source": [
    "from state_agent.agents.subnets.actors import SteeringActor, DriftActor, SpeedActor\n",
    "from state_agent.agents.subnets.planners import PlayerPuckGoalPlannerActor\n",
    "from state_agent.agents.subnets.agents import Agent, BaseTeam\n",
    "from state_agent.agents.subnets.utils import Rollout, run_soccer_agent, rollout_many, show_trajectory_histogram, load_model, save_model\n",
    "from state_agent.agents.subnets.rewards import SoccerBallDistanceObjective\n",
    "from state_agent.agents.subnets.features import get_distance_cart_to_puck\n",
    "from state_agent.trainers.train_policy_gradient import reinforce, SoccerReinforcementConfiguration\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3195c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(), train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializations(actor_class):    \n",
    "    distance_objective = SoccerBallDistanceObjective(150)\n",
    "    many_actors = [actor_class() for i in range(100)]\n",
    "\n",
    "    data = rollout_many([\n",
    "        Agent(actor, accel=0.05) for actor in many_actors\n",
    "    ], randomize=True, n_steps=600)\n",
    "\n",
    "    good_initialization = many_actors[ np.argmax([distance_objective.calculate_state_score(d[-1]) for d in data]) ]\n",
    "    bad_initialization = many_actors[ np.argmin([distance_objective.calculate_state_score(d[-1]) for d in data]) ]\n",
    "    \n",
    "    return good_initialization, bad_initialization\n",
    "\n",
    "good_initialization, _ = get_initializations(SteeringActor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_initialization = best_steering_net\n",
    "action_net = copy.deepcopy(good_initialization.action_net)\n",
    "actors = [SteeringActor(action_net)]\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    return Agent(*args, accel=0.05, target_speed=10.0, **kwargs)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_steering_net = reinforce(actors[0], actors, config, \n",
    "                              n_epochs=5, n_iterations=500, n_trajectories=200, n_validations=100, T=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(best_steering_net), accel=0.1), randomize=True, ball_location=[-6., -60.], player_location=[-20, 0, -50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8eaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best_steering_net\n",
    "steering_actor = SteeringActor(best_steering_net)\n",
    "steering_actor.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a98817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Steering Actor\n",
    "steering_actor = SteeringActor()\n",
    "steering_actor.load_model()\n",
    "best_steering_net = steering_actor.action_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the speed actor\n",
    "good_initialization_speed, _ = get_initializations(SpeedActor)\n",
    "\n",
    "action_net = copy.deepcopy(good_initialization_speed.action_net)\n",
    "actors = [SteeringActor(best_steering_net, train=False), SpeedActor(action_net)]\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    reverse = np.random.uniform(0, 1) < 0.1\n",
    "    speed = np.random.normal(10, 5) * (-1.0 if reverse else 1.0)\n",
    "    return Agent(*args, target_speed=speed, **kwargs)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_speed_net = reinforce(actors[1], actors, config, \n",
    "                              n_epochs=5, n_iterations=500, n_trajectories=200, n_validations=100, T=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee85cd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = run_soccer_agent(Agent(SteeringActor(best_steering_net), SpeedActor(best_speed_net), target_speed=-5.0), randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best_speed_net\n",
    "speed_actor = SpeedActor(best_speed_net)\n",
    "speed_actor.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Speed Actor\n",
    "speed_actor = SpeedActor()\n",
    "speed_actor.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ec216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the player goal scoring planner\n",
    "\n",
    "def create_planner_actor():\n",
    "    return PlayerPuckGoalPlannerActor(\n",
    "        SpeedActor(best_speed_net),\n",
    "        SteeringActor(best_steering_net)\n",
    "    )\n",
    "\n",
    "def gen_agent(*args, **kwargs):\n",
    "    return Agent(*args, accel=0.1, **kwargs)\n",
    "\n",
    "def rollout_initializer(world_info, randomize, **kwargs):\n",
    "\n",
    "    #wall_case = np.random.uniform(0, 1.0) < 0\n",
    "    wall_case = False\n",
    "\n",
    "    # generate a rollout where the player and puck are near each other\n",
    "    #position = np.random.uniform(low=-10, high=10, size=(2))\n",
    "    offset = [np.random.uniform(-0.2, 0.2), -6]\n",
    "    world_info.set_ball_location((position[0], 1, position[1]), (0, 0, 0))\n",
    "\n",
    "    if wall_case:\n",
    "        player_location = [20, 1, 62]\n",
    "    else:\n",
    "        player_location = [position[0] + offset[0], 1, position[1] + offset[1]]\n",
    "    world_info.set_kart_location(0, player_location, [0, 0, 0, 1.0], 0)\n",
    "\n",
    "def post_epoch(actor, context):\n",
    "    # show a histogram of distances\n",
    "    show_trajectory_histogram(context.trajectories, get_distance_cart_to_puck, max=60, bins=20)\n",
    "    plt.hist(context.rewards)\n",
    "    plt.title(\"Rewards\")\n",
    "    plt.show()\n",
    "    plt.hist(context.actions, 4, range=(0, 4))\n",
    "    plt.title(\"Actions\")\n",
    "    plt.show()\n",
    "    print(np.sum(np.array(context.actions) == 0), np.sum(np.array(context.actions) == 1), np.sum(np.array(context.actions) == 2))\n",
    "\n",
    "good_initialization_planner, _ = get_initializations(create_planner_actor)\n",
    "\n",
    "#action_net = copy.deepcopy(good_initialization_planner.action_net)\n",
    "actors = [PlayerPuckGoalPlannerActor(SpeedActor(best_speed_net), SteeringActor(best_steering_net), action_net)]\n",
    "\n",
    "# give it a positive random weight to make it the worst case\n",
    "#action_net.net[0].weight = torch.nn.Parameter(torch.Tensor([[np.random.uniform(0, 1.0)]]))\n",
    "\n",
    "#starting_weight = action_net.net[0].weight.clone()\n",
    "#print(\"Starting weight\", action_net.net[0].weight)\n",
    "\n",
    "# configuration\n",
    "config = SoccerReinforcementConfiguration()\n",
    "config.agent = gen_agent\n",
    "config.rollout_initializer = rollout_initializer\n",
    "\n",
    "# iterations is high relatively here to help force a good outcome from a bad initialization\n",
    "best_planner_net = reinforce(actors[0], actors, config,\n",
    "                              n_epochs=4, n_iterations=1000, n_trajectories=200, n_validations=20, T=1,\n",
    "                              epoch_post_process=post_epoch\n",
    "                    )\n",
    "print(best_planner_net.net[0].weight)\n",
    "print(action_net.net[0].weight)\n",
    "\n",
    "#assert(action_net.net[0].weight != starting_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75589ada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_planner_net = action_net\n",
    "data = run_soccer_agent(Agent(\n",
    "    PlayerPuckGoalPlannerActor(\n",
    "        speed_net=SpeedActor(best_speed_net),\n",
    "        steering_net=SteeringActor(best_steering_net),\n",
    "        action_net=best_planner_net\n",
    "    ), accel=0.1\n",
    "), randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Planner Actor\n",
    "planner_actor = PlayerPuckGoalPlannerActor(best_planner_net)\n",
    "planner_actor.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the planner actor\n",
    "planner_actor = PlayerPuckGoalPlannerActor(speed_net=SpeedActor(best_speed_net),\n",
    "                                        steering_net=SteeringActor(best_steering_net))\n",
    "planner_actor.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e0acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_rollout_soccer = Rollout.remote(400, 300, mode=\"soccer\", players=[(0, False, \"tux\")], num_karts=1)\n",
    "data = run_soccer_agent(Agent( \n",
    "    PlayerPuckGoalPlannerActor(\n",
    "        speed_net=SpeedActor(best_speed_net),\n",
    "        steering_net=SteeringActor(best_steering_net), \n",
    "        action_net=best_planner_net        \n",
    "    )\n",
    "), rollout=viz_rollout_soccer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851efde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
